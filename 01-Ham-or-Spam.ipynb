{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ham ya da Spam?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ¯ Bu gÃ¶revin amacÄ±, e-postalarÄ± **spam (1)** veya **normal e-posta (0)** olarak sÄ±nÄ±flandÄ±rmaktÄ±r.\n",
    "\n",
    "ğŸ§¹ Ä°lk olarak, bu metin verilerine **temizleme (cleaning)** teknikleri uygulanacaktÄ±r.\n",
    "\n",
    "ğŸ‘©ğŸ»â€ğŸ”¬ ArdÄ±ndan, temizlenmiÅŸ metinler **sayÄ±sal bir gÃ¶sterime** dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lecektir.\n",
    "\n",
    "âœ‰ï¸ Son olarak, her bir e-postayÄ± spam mÄ± yoksa normal mi olduÄŸunu sÄ±nÄ±flandÄ±rmak iÃ§in  \n",
    "***Multinomial Naive Bayes*** modeli uygulanacaktÄ±r.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (0) NTLK kÃ¼tÃ¼phanesi (DoÄŸal Dil AraÃ§ Seti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/berkayturhan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/berkayturhan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/berkayturhan/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/berkayturhan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/berkayturhan/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk'yi ilk kez iÃ§e aktarÄ±rken, birkaÃ§ yerleÅŸik kÃ¼tÃ¼phaneyi de indirmemiz gerekir.\n",
    "\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')      # nltk<3.9.0 iÃ§in\n",
    "nltk.download('punkt_tab')  # nltk>=3.9.0 iÃ§in\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  spam\n",
       "0  Subject: naturally irresistible your corporate...     1\n",
       "1  Subject: the stock trading gunslinger  fanny i...     1\n",
       "2  Subject: unbelievable new homes made easy  im ...     1\n",
       "3  Subject: 4 color printing special  request add...     1\n",
       "4  Subject: do not have money , get software cds ...     1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"https://d32aokrjazspmn.cloudfront.net/materials/ham_spam_emails.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1) (Metin) veri setinin temizlenmesi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Veri kÃ¼mesi, ham [0] veya spam [1] olarak sÄ±nÄ±flandÄ±rÄ±lan e-postalardan oluÅŸur. Tahmin modelini eÄŸitmeden Ã¶nce veri kÃ¼mesini temizlemeniz gerekir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.1) Noktalama Ä°ÅŸaretlerini KaldÄ±r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ Noktalama iÅŸaretlerini kaldÄ±rmak iÃ§in bir iÅŸlev oluÅŸturun. Bunu `text` sÃ¼tununa uygulayÄ±n ve Ã§Ä±ktÄ±yÄ± `clean_text` adlÄ± veri Ã§erÃ§evesinin yeni bir sÃ¼tununa ekleyin. â“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "      <td>Subject naturally irresistible your corporate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "      <td>1</td>\n",
       "      <td>Subject the stock trading gunslinger  fanny is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Subject unbelievable new homes made easy  im w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "      <td>1</td>\n",
       "      <td>Subject 4 color printing special  request addi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Subject do not have money  get software cds fr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  spam  \\\n",
       "0  Subject: naturally irresistible your corporate...     1   \n",
       "1  Subject: the stock trading gunslinger  fanny i...     1   \n",
       "2  Subject: unbelievable new homes made easy  im ...     1   \n",
       "3  Subject: 4 color printing special  request add...     1   \n",
       "4  Subject: do not have money , get software cds ...     1   \n",
       "\n",
       "                                          clean_text  \n",
       "0  Subject naturally irresistible your corporate ...  \n",
       "1  Subject the stock trading gunslinger  fanny is...  \n",
       "2  Subject unbelievable new homes made easy  im w...  \n",
       "3  Subject 4 color printing special  request addi...  \n",
       "4  Subject do not have money  get software cds fr...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "# AdÄ±m 1: Temizleme iÅŸlemini yapacak fonskiyonu tanÄ±mlÄ±yoruz.\n",
    "def remove_punctuation(text):\n",
    "    # Metnin iÃ§indeki her bir harfi/karakteri (char) tek tek gezeriz.\n",
    "    # EÄŸer bu karakter, string.punctuation (noktalama iÅŸaretleri) iÃ§inde YOKSA (not in) onu alÄ±rÄ±z.\n",
    "    # \"\".join() ile de bu kalan harfleri tekrar birleÅŸtirip kelime/cÃ¼mle haline getiririz.\n",
    "    clean_text = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    return clean_text\n",
    "\n",
    "# AdÄ±m 2: Fonksiyonu veri setine uygulama\n",
    "# 'text' sÃ¼tunundaki her bir satÄ±ra bu fonksiyonu uygula (apply) ve\n",
    "# 'clean_text' adÄ±nda yeni bir sÃ¼tuna kaydet.\n",
    "df['clean_text'] = df['text'].apply(remove_punctuation)\n",
    "\n",
    "# AdÄ±m 3: Sonucu gÃ¶rmek iÃ§in ilk 5 satÄ±rÄ± yazdÄ±ralÄ±m\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.2) KÃ¼Ã§Ã¼k Harf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ Metni kÃ¼Ã§Ã¼k harfe Ã§eviren bir iÅŸlev oluÅŸturun. Bunu `clean_text`'e uygulayÄ±n â“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject naturally irresistible your corporate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject the stock trading gunslinger  fanny is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject unbelievable new homes made easy  im w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject 4 color printing special  request addi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject do not have money  get software cds fr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  spam  \\\n",
       "0  Subject: naturally irresistible your corporate...     1   \n",
       "1  Subject: the stock trading gunslinger  fanny i...     1   \n",
       "2  Subject: unbelievable new homes made easy  im ...     1   \n",
       "3  Subject: 4 color printing special  request add...     1   \n",
       "4  Subject: do not have money , get software cds ...     1   \n",
       "\n",
       "                                          clean_text  \n",
       "0  subject naturally irresistible your corporate ...  \n",
       "1  subject the stock trading gunslinger  fanny is...  \n",
       "2  subject unbelievable new homes made easy  im w...  \n",
       "3  subject 4 color printing special  request addi...  \n",
       "4  subject do not have money  get software cds fr...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. AdÄ±m: Metni kÃ¼Ã§Ã¼k harfe Ã§evirelim\n",
    "def lower_text(text):\n",
    "    # .lower() metodu, python'da stringleri kÃ¼Ã§Ã¼ltmek iÃ§in kullanÄ±lÄ±r.\n",
    "    return text.lower()\n",
    "\n",
    "# 2. AdÄ±m: Fonksiyonu 'clean_text' sÃ¼tununa uygulayalÄ±m\n",
    "# Dikkat: ArtÄ±k iÅŸlemi bir Ã¶nceki adÄ±mda oluÅŸturduÄŸumuz 'clean_text' sÃ¼tunu Ã¼zerinde yapÄ±yoruz.\n",
    "df['clean_text'] = df['clean_text'].apply(lower_text)\n",
    "\n",
    "# 3. AdÄ±m: Kontrol\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.3) SayÄ±larÄ± KaldÄ±r"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ Metinden sayÄ±larÄ± kaldÄ±rmak iÃ§in bir iÅŸlev oluÅŸturun. Bunu `clean_text`'e uygulayÄ±n â“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject naturally irresistible your corporate ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject the stock trading gunslinger  fanny is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject unbelievable new homes made easy  im w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject  color printing special  request addit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject do not have money  get software cds fr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  spam  \\\n",
       "0  Subject: naturally irresistible your corporate...     1   \n",
       "1  Subject: the stock trading gunslinger  fanny i...     1   \n",
       "2  Subject: unbelievable new homes made easy  im ...     1   \n",
       "3  Subject: 4 color printing special  request add...     1   \n",
       "4  Subject: do not have money , get software cds ...     1   \n",
       "\n",
       "                                          clean_text  \n",
       "0  subject naturally irresistible your corporate ...  \n",
       "1  subject the stock trading gunslinger  fanny is...  \n",
       "2  subject unbelievable new homes made easy  im w...  \n",
       "3  subject  color printing special  request addit...  \n",
       "4  subject do not have money  get software cds fr...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. AdÄ±m: SayÄ±larÄ± temizleyen fonksiyonu yazalÄ±m\n",
    "def remove_numbers(text):\n",
    "    # .isdigit() metodu, bir karakterin sayÄ± olup olmadÄ±ÄŸÄ±nÄ± kontrol eder.\n",
    "    # EÄŸer karakter sayÄ± DEÄÄ°LSE (not char.isdigit()), onu listeye ekle ve birleÅŸtir.\n",
    "    text = \"\".join([char for char in text if not char.isdigit()])\n",
    "    return text\n",
    "\n",
    "# 2. AdÄ±m: Fonksiyonu 'clean_text' sÃ¼tununa uygulayalÄ±m\n",
    "df['clean_text'] = df['clean_text'].apply(remove_numbers)\n",
    "\n",
    "# 3. AdÄ±m: Kontrol\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.4) StopWords'Ã¼ kaldÄ±rÄ±n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ Metinden durdurma kelimelerini kaldÄ±rmak iÃ§in bir iÅŸlev oluÅŸturun. Bunu `clean_text`'e uygulayÄ±n. â“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject naturally irresistible corporate ident...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject stock trading gunslinger fanny merrill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject unbelievable new homes made easy im wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject color printing special request additio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject money get software cds software compat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  spam  \\\n",
       "0  Subject: naturally irresistible your corporate...     1   \n",
       "1  Subject: the stock trading gunslinger  fanny i...     1   \n",
       "2  Subject: unbelievable new homes made easy  im ...     1   \n",
       "3  Subject: 4 color printing special  request add...     1   \n",
       "4  Subject: do not have money , get software cds ...     1   \n",
       "\n",
       "                                          clean_text  \n",
       "0  subject naturally irresistible corporate ident...  \n",
       "1  subject stock trading gunslinger fanny merrill...  \n",
       "2  subject unbelievable new homes made easy im wa...  \n",
       "3  subject color printing special request additio...  \n",
       "4  subject money get software cds software compat...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# 1. AdÄ±m: Durdurma kelimelerini temizleyen fonksiyon\n",
    "def remove_stopwords(text):\n",
    "    # a. Ä°ngilizce stopword listesini yÃ¼klÃ¼yoruz (verimiz Ä°ngilizce olduÄŸu iÃ§in)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    # b. CÃ¼mleyi kelimelerine ayÄ±rÄ±yoruz (Tokenization)\n",
    "    # \"hello world\" -> [\"hello\", \"world\"] olur.\n",
    "    word_tokens = word_tokenize(text)\n",
    "    \n",
    "    # c. EÄŸer kelime stop_words listesinde YOKSA onu alÄ±yoruz.\n",
    "    # [w for w in word_tokens if not w in stop_words]\n",
    "    filtered_text = [w for w in word_tokens if not w in stop_words]\n",
    "    \n",
    "    # d. Kelimeleri tekrar boÅŸlukla birleÅŸtirip cÃ¼mle haline getiriyoruz\n",
    "    return \" \".join(filtered_text)\n",
    "\n",
    "# 2. AdÄ±m: Fonksiyonu uygulama\n",
    "df['clean_text'] = df['clean_text'].apply(remove_stopwords)\n",
    "\n",
    "# 3. AdÄ±m: Kontrol\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1.5) Lemmatize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ Metni lemmatize etmek iÃ§in bir fonksiyon oluÅŸturun. Ã‡Ä±ktÄ±nÄ±n bir kelime listesi deÄŸil, tek bir dize olduÄŸundan emin olun. Bunu `clean_text`'e uygulayÄ±n. â“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject naturally irresistible corporate ident...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject stock trading gunslinger fanny merrill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject unbelievable new home made easy im wan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject color printing special request additio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "      <td>1</td>\n",
       "      <td>subject money get software cd software compati...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  spam  \\\n",
       "0  Subject: naturally irresistible your corporate...     1   \n",
       "1  Subject: the stock trading gunslinger  fanny i...     1   \n",
       "2  Subject: unbelievable new homes made easy  im ...     1   \n",
       "3  Subject: 4 color printing special  request add...     1   \n",
       "4  Subject: do not have money , get software cds ...     1   \n",
       "\n",
       "                                          clean_text  \n",
       "0  subject naturally irresistible corporate ident...  \n",
       "1  subject stock trading gunslinger fanny merrill...  \n",
       "2  subject unbelievable new home made easy im wan...  \n",
       "3  subject color printing special request additio...  \n",
       "4  subject money get software cd software compati...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# 1. AdÄ±m: Lemmatize fonksiyonunu tanÄ±mla\n",
    "def lemmatize_text(text):\n",
    "    # Lemmatizer nesnesini oluÅŸturuyoruz (AraÃ§ kutusundan aleti Ã§Ä±karÄ±yoruz)\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    # CÃ¼mleyi kelimelere bÃ¶lÃ¼yoruz\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Her bir kelimeyi (token) tek tek kÃ¶kÃ¼ne Ã§eviriyoruz\n",
    "    # lemmatizer.lemmatize(word) -> kelimenin kÃ¶kÃ¼nÃ¼ verir\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    \n",
    "    # Kelimeleri tekrar birleÅŸtirip tek bir string (yazÄ±) yapÄ±yoruz\n",
    "    return \" \".join(lemmatized_tokens)\n",
    "\n",
    "# 2. AdÄ±m: Fonksiyonu uygula\n",
    "df['clean_text'] = df['clean_text'].apply(lemmatize_text)\n",
    "\n",
    "# 3. AdÄ±m: Kontrol\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (2) Bag-of-Words Modellemesi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.1) Metin verilerini sayÄ±lara dÃ¶nÃ¼ÅŸtÃ¼rme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ `clean_text`'i varsayÄ±lan CountVectorizer ile Bag-of-Words temsiline vektÃ¶rleÅŸtirin. `X_bow` olarak kaydedin. â“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5728, 30988)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# 1. AdÄ±m: VektÃ¶rleÅŸtiriciyi (Sayma Makinesi) baÅŸlatÄ±yoruz\n",
    "# Bu araÃ§, kelimeleri saymak iÃ§in ayarlanmÄ±ÅŸ bir robot gibidir.\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# 2. AdÄ±m: Veriyi makineye verip dÃ¶nÃ¼ÅŸtÃ¼rÃ¼yoruz (fit & transform)\n",
    "# fit: TÃ¼m kelime havuzunu (sÃ¶zlÃ¼ÄŸÃ¼) Ã¶ÄŸrenir.\n",
    "# transform: Her satÄ±rdaki kelimeleri sayÄ±p matrise Ã§evirir.\n",
    "X_bow = vectorizer.fit_transform(df['clean_text'])\n",
    "\n",
    "# 3. AdÄ±m: Sonucu kontrol edelim (BoyutlarÄ±na bakalÄ±m)\n",
    "# Ã‡Ä±ktÄ± (SatÄ±r SayÄ±sÄ±, Kelime SayÄ±sÄ±) ÅŸeklinde olacak.\n",
    "print(X_bow.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2.2) Ã‡ok terimli Naive Bayes Modellemesi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "â“ MultinomialNB modelini bag-of-words verileriyle Ã§apraz doÄŸrulayÄ±n. Modelin doÄŸruluÄŸunu puanlayÄ±n. â“"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DoÄŸruluk Skoru (Accuracy): 0.9895252901681946\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# 1. AdÄ±m: Hedef deÄŸiÅŸkenimizi (y) belirliyoruz.\n",
    "# Neyin tahmin edileceÄŸini sÃ¶ylÃ¼yoruz: 'spam' sÃ¼tunu (0 veya 1 deÄŸerleri)\n",
    "y = df['spam']\n",
    "\n",
    "# 2. AdÄ±m: Modeli tanÄ±mlÄ±yoruz (Multinomial Naive Bayes)\n",
    "nb_model = MultinomialNB()\n",
    "\n",
    "# 3. AdÄ±m: Ã‡apraz DoÄŸrulama (Cross Validation) ile modeli zorluyoruz\n",
    "# nb_model: Modelimiz\n",
    "# X_bow: Ders notlarÄ± (Kelimeler)\n",
    "# y: Cevap anahtarÄ± (Spam mi deÄŸil mi?)\n",
    "# cv=5: SÄ±navÄ± 5 kere tekrarla\n",
    "scores = cross_val_score(nb_model, X_bow, y, cv=5)\n",
    "\n",
    "# 4. AdÄ±m: Sonucu yazdÄ±rma\n",
    "# 5 sÄ±navÄ±n ortalamasÄ±nÄ± alÄ±yoruz.\n",
    "print(\"DoÄŸruluk Skoru (Accuracy):\", scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ Tebrikler!\n",
    "\n",
    "ğŸ’¾ Not defterinizi git add/commit/push yapmayÄ± unutmayÄ±n...\n",
    "\n",
    "ğŸš€ ... ve bir sonraki challenge'a geÃ§in!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workintech",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
